{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests beautifulsoup4 pandas json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Trang 3 request thành công.\n",
      "[INFO] Trang 4 request thành công.\n",
      "[INFO] Trang 5 request thành công.\n",
      "[INFO] Trang 6 request thành công.\n",
      "[INFO] Trang 7 request thành công.\n",
      "[INFO] Trang 8 request thành công.\n",
      "[INFO] Trang 9 request thành công.\n",
      "[INFO] Trang 10 request thành công.\n",
      "[INFO] Crawl hoàn tất. Tổng số dòng crawl được: 10\n",
      "[INFO] File CSV lưu tại: house_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# Hàm parse_vn_time_str\n",
    "# =============================================================================\n",
    "def parse_vn_time_str(time_str):\n",
    "    \"\"\"\n",
    "    Chuyển đổi chuỗi thời gian tiếng Việt (ví dụ: \"3 ngày trước\", \"5 giờ trước\",\n",
    "    \"hôm qua\", \"30 giây trước\") thành chuỗi định dạng \"dd/mm/yy\".\n",
    "    \n",
    "    Nếu chuỗi là \"hôm qua\", trừ 1 ngày khỏi thời điểm hiện tại.\n",
    "    Nếu chuỗi có số và đơn vị (ngày, giờ, phút, giây) theo mẫu \"x ... trước\",\n",
    "    trừ tương ứng khỏi thời điểm hiện tại.\n",
    "    Nếu không parse được, mặc định trả về thời điểm hiện tại.\n",
    "    \n",
    "    Parameters:\n",
    "        time_str (str): Chuỗi thời gian tiếng Việt.\n",
    "        \n",
    "    Returns:\n",
    "        str: Chuỗi thời gian định dạng \"dd/mm/yy\".\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()         # Lấy thời điểm hiện tại\n",
    "    if not time_str:                        # Nếu chuỗi rỗng hoặc None\n",
    "        return None\n",
    "    time_str = time_str.strip().lower()     # Loại bỏ khoảng trắng thừa và chuyển về chữ thường\n",
    "\n",
    "    # Nếu chuỗi chứa \"hôm qua\", trừ đi 1 ngày\n",
    "    if \"hôm qua\" in time_str:\n",
    "        dt = now - datetime.timedelta(days=1)\n",
    "    else:\n",
    "        # Dùng biểu thức chính quy để tìm số và đơn vị (ngày, giờ, phút, giây)\n",
    "        match = re.match(r\"(\\d+)\\s+(ngày|giờ|phút|giây)\\s+trước\", time_str)\n",
    "        if match:\n",
    "            val = int(match.group(1))      # Lấy số lượng (ví dụ: 3, 5, 30)\n",
    "            unit = match.group(2)          # Lấy đơn vị (\"ngày\", \"giờ\", \"phút\", \"giây\")\n",
    "            if unit == \"ngày\":\n",
    "                dt = now - datetime.timedelta(days=val)\n",
    "            elif unit == \"giờ\":\n",
    "                dt = now - datetime.timedelta(hours=val)\n",
    "            elif unit == \"phút\":\n",
    "                dt = now - datetime.timedelta(minutes=val)\n",
    "            elif unit == \"giây\":\n",
    "                dt = now - datetime.timedelta(seconds=val)\n",
    "        else:\n",
    "            # Nếu không khớp biểu thức, mặc định sử dụng thời điểm hiện tại\n",
    "            dt = now\n",
    "\n",
    "    # Trả về chuỗi định dạng \"dd/mm/yy\"\n",
    "    return dt.strftime(\"%d/%m/%y\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CẤU HÌNH REQUEST\n",
    "# =============================================================================\n",
    "\n",
    "# Cookie (nếu cần) để vượt qua hạn chế của server\n",
    "cookies = {\n",
    "    '_cfuvid': '8Ts694nmmK71_7TANcDMtfYe0q6_TtIxmRoeEi2V.pM-1739949090257-0.0.1.1-604800000'\n",
    "}\n",
    "\n",
    "# Headers giả lập trình duyệt\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Accept-Language': 'vi,en;q=0.9,en-GB;q=0.8,en-US;q=0.7',\n",
    "    'Referer': 'https://www.nhatot.com/',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Origin': 'https://www.nhatot.com',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Site': 'cross-site'\n",
    "}\n",
    "\n",
    "# Tham số truy vấn cho API của Chợ Tốt\n",
    "params = {\n",
    "    'limit': '10',                     # Số tin đăng mỗi trang\n",
    "    'protection_entitlement': 'true',\n",
    "    'page': '2',                        # Số trang (sẽ được cập nhật trong vòng lặp)\n",
    "    'cg': '1000',                      # Mã danh mục (ví dụ: Nhà đất)\n",
    "    'region_v2': '12000',              # Khu vực (ví dụ: Hà Nội)\n",
    "    'st': 's,k',                       # Trạng thái sản phẩm\n",
    "    'key_param_included': 'true'\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CẤU HÌNH CRAWL & LƯU FILE\n",
    "# =============================================================================\n",
    "\n",
    "MAX_PAGES = 10               # Số trang tối đa cần crawl\n",
    "CHUNK_SIZE = 50                # Số trang mỗi khối để ghi ra CSV\n",
    "OUTPUT_FILE = 'house_data.csv'   # Tên file CSV đầu ra\n",
    "\n",
    "# Nếu file CSV đã tồn tại, xoá nó để lưu dữ liệu mới\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    os.remove(OUTPUT_FILE)\n",
    "\n",
    "# Global counter dùng để đếm số dòng đã ghi (dùng làm STT)\n",
    "global_row_counter = 0\n",
    "\n",
    "# Danh sách tạm chứa dữ liệu crawl được (dạng list of dict)\n",
    "house_data_chunk = []\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# HÀM LƯU DỮ LIỆU RA FILE CSV\n",
    "# =============================================================================\n",
    "def save_chunk_to_csv(data_list, filename):\n",
    "    \"\"\"\n",
    "    Lưu danh sách dữ liệu (list of dict) ra file CSV theo chế độ append.\n",
    "    \n",
    "    Các bước thực hiện:\n",
    "      1. Tạo DataFrame từ danh sách dữ liệu.\n",
    "      2. Loại bỏ các bản ghi trùng lặp dựa trên cột 'ID'.\n",
    "      3. Ép kiểu số cho các cột quan trọng (nếu chuyển không được, gán NaN).\n",
    "      4. Chuyển đổi cột thời gian sang kiểu datetime theo định dạng \"dd/mm/yy\".\n",
    "      5. Gán index liên tục (STT) dựa trên biến global_row_counter.\n",
    "      6. Lưu DataFrame ra file CSV (append mode), sử dụng index với nhãn \"STT\".\n",
    "    \n",
    "    Parameters:\n",
    "        data_list (list): Danh sách dữ liệu crawl được.\n",
    "        filename (str): Tên file CSV để lưu.\n",
    "    \"\"\"\n",
    "    if not data_list:\n",
    "        return\n",
    "\n",
    "    global global_row_counter  # Sử dụng biến toàn cục để cập nhật STT\n",
    "\n",
    "    # Tạo DataFrame từ danh sách dữ liệu\n",
    "    df_chunk = pd.DataFrame(data_list)\n",
    "\n",
    "    # Loại bỏ các bản ghi trùng lặp dựa trên cột 'ID'\n",
    "    df_chunk.drop_duplicates(subset=['ID', 'Thoi_Gian'], keep='first', inplace=True)\n",
    "\n",
    "\n",
    "    # Ép kiểu số cho các cột: nếu chuyển đổi không được, gán giá trị NaN\n",
    "    df_chunk['Dien_Tich'] = pd.to_numeric(df_chunk['Dien_Tich'], errors='coerce')\n",
    "    df_chunk['Gia'] = pd.to_numeric(df_chunk['Gia'], errors='coerce')\n",
    "    df_chunk['Gia/m2'] = pd.to_numeric(df_chunk['Gia/m2'], errors='coerce')\n",
    "    df_chunk['So_Tang'] = pd.to_numeric(df_chunk['So_Tang'], errors='coerce')\n",
    "    df_chunk['So_Phong_Ngu'] = pd.to_numeric(df_chunk['So_Phong_Ngu'], errors='coerce')\n",
    "    df_chunk['So_Nha_Ve_Sinh'] = pd.to_numeric(df_chunk['So_Nha_Ve_Sinh'], errors='coerce')\n",
    "\n",
    "    # Chuyển đổi cột Thoi_Gian sang kiểu datetime theo định dạng \"dd/mm/yy\"\n",
    "    df_chunk['Thoi_Gian'] = pd.to_datetime(df_chunk['Thoi_Gian'], format='%d/%m/%y', errors='coerce')\n",
    "\n",
    "    # Gán lại index cho DataFrame sao cho STT nối tiếp từ global_row_counter\n",
    "    df_chunk.index = range(global_row_counter, global_row_counter + len(df_chunk))\n",
    "    global_row_counter += len(df_chunk)\n",
    "\n",
    "    # Ghi DataFrame ra file CSV ở chế độ append:\n",
    "    # Nếu file chưa tồn tại thì ghi header, còn nếu đã tồn tại thì không ghi header.\n",
    "    header_needed = not os.path.exists(filename)\n",
    "    df_chunk.to_csv(filename, mode='a', index=True, index_label='STT', header=header_needed)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# QUÁ TRÌNH CRAWL DỮ LIỆU\n",
    "# =============================================================================\n",
    "for i in range(3, MAX_PAGES + 1):\n",
    "    # Cập nhật số trang cho tham số truy vấn\n",
    "    params['page'] = i\n",
    "\n",
    "    try:\n",
    "        # Gửi request GET đến API của Chợ Tốt\n",
    "        response = requests.get(\n",
    "            'https://gateway.chotot.com/v1/public/ad-listing',\n",
    "            #headers=headers,\n",
    "            params=params,\n",
    "            #cookies=cookies,\n",
    "            timeout=30\n",
    "        )\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'[ERROR] Trang {i} gặp lỗi: {e}')\n",
    "        continue  # Nếu lỗi, bỏ qua trang hiện tại\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f'[INFO] Trang {i} request thành công.')\n",
    "        # Lấy danh sách tin đăng (nếu không có, trả về list rỗng)\n",
    "        ads_list = response.json().get('ads', [])\n",
    "        \n",
    "        # Nếu không còn tin đăng, dừng crawl sớm (tùy chọn)\n",
    "        if not ads_list:\n",
    "            print(f'[INFO] Không còn tin đăng ở trang {i}, dừng crawl.')\n",
    "            break\n",
    "\n",
    "        # Xử lý từng tin đăng trong danh sách\n",
    "        for record in ads_list:\n",
    "            # Lấy trường \"date\" và chuyển đổi sang định dạng \"dd/mm/yy\"\n",
    "            raw_date = record.get('date')\n",
    "            converted_date = parse_vn_time_str(raw_date) if raw_date else None\n",
    "\n",
    "            # Thêm thông tin tin đăng vào danh sách tạm house_data_chunk\n",
    "            house_data_chunk.append({\n",
    "                'ID': record.get('ad_id'),\n",
    "                'Dien_Tich': record.get('living_size'),\n",
    "                'Gia': record.get('price'),\n",
    "                'Gia/m2': record.get('price_million_per_m2'),\n",
    "                'Ten_Duong': record.get('street_name'),\n",
    "                'Ten_Phuong': record.get('ward_name'),\n",
    "                'Ten_Quan': record.get('area_name'),\n",
    "                'Ten_Tinh': record.get('region_name'),\n",
    "                'Loai_Hinh': record.get('category_name'),\n",
    "                'So_Tang': record.get('floors'),\n",
    "                'So_Phong_Ngu': record.get('rooms'),\n",
    "                'So_Nha_Ve_Sinh': record.get('toilets'),\n",
    "                'Thoi_Gian': converted_date,   # Thời gian đã chuyển đổi\n",
    "                'Phap_Ly': record.get('property_legal_document')\n",
    "            })\n",
    "    else:\n",
    "        print(f'[WARN] Trang {i} request thất bại, status code: {response.status_code}')\n",
    "    \n",
    "    # Nghỉ ngẫu nhiên từ 1 đến 3 giây để tránh gửi request quá nhanh\n",
    "    #time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    # Sau mỗi CHUNK_SIZE trang, lưu dữ liệu tạm ra file CSV và xoá danh sách tạm\n",
    "    if i % CHUNK_SIZE == 0:\n",
    "        save_chunk_to_csv(house_data_chunk, OUTPUT_FILE)\n",
    "        house_data_chunk.clear()\n",
    "        # Có thể thêm thời gian nghỉ dài hơn sau mỗi khối nếu cần (ví dụ: time.sleep(60))\n",
    "\n",
    "# Nếu còn dữ liệu chưa được lưu, lưu nốt vào file CSV\n",
    "if house_data_chunk:\n",
    "    save_chunk_to_csv(house_data_chunk, OUTPUT_FILE)\n",
    "    house_data_chunk.clear()\n",
    "\n",
    "# =============================================================================\n",
    "# XÓA những hàng có ít nhất 1 cột trống (NaN)\n",
    "# =============================================================================\n",
    "# Đọc lại file CSV để đảm bảo tất cả dữ liệu đã được xử lý\n",
    "df = pd.read_csv(OUTPUT_FILE)\n",
    "# Xóa các hàng có bất kỳ giá trị nào NaN\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# Lưu lại file CSV sau khi xóa những hàng có cột trống\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "# =============================================================================\n",
    "# HIỂN THỊ TỔNG SỐ DÒNG CRAWL ĐƯỢC\n",
    "# =============================================================================\n",
    "print(f'[INFO] Crawl hoàn tất. Tổng số dòng crawl được: {global_row_counter}')\n",
    "print(f'[INFO] File CSV lưu tại: {OUTPUT_FILE}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
